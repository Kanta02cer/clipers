#!/usr/bin/env python3
"""
çµ±åˆYouTubeå‹•ç”»åˆ†æã‚·ã‚¹ãƒ†ãƒ 
YouTube Data API v3ã€yt-dlpã€Gemini AIã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æã‚’çµ±åˆ
"""

import os
import sys
import json
import logging
import tempfile
import re
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime

# YouTube APIé–¢é€£
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# å‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–¢é€£
import yt_dlp

# AIåˆ†æãƒ»ãƒ­ã‚¸ãƒƒã‚¯é–¢é€£
from gemini_analyzer import GeminiAnalyzer
from analysis_logic import VVPScoreCalculator
from content_analyzer import ContentAnalyzer

# è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class IntegratedYouTubeAnalyzer:
    """çµ±åˆYouTubeå‹•ç”»åˆ†æå™¨"""
    
    def __init__(self, youtube_api_key: str, gemini_api_key: str):
        """
        åˆæœŸåŒ–
        
        Args:
            youtube_api_key: YouTube Data API v3ã‚­ãƒ¼
            gemini_api_key: Google Gemini APIã‚­ãƒ¼
        """
        self.youtube_api_key = youtube_api_key
        
        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–
        self.youtube_client = self._init_youtube_client(youtube_api_key)
        self.gemini_analyzer = GeminiAnalyzer(gemini_api_key)
        self.vvp_calculator = VVPScoreCalculator()
        self.content_analyzer = ContentAnalyzer()
        
        self.temp_dir = tempfile.mkdtemp(prefix='youtube_analyzer_')
        logger.info(f"ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {self.temp_dir}")

    def _init_youtube_client(self, api_key: str):
        try:
            client = build('youtube', 'v3', developerKey=api_key)
            logger.info("YouTube APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–æˆåŠŸ")
            return client
        except Exception as e:
            logger.error(f"YouTube APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def extract_video_id(self, url: str) -> Optional[str]:
        """
        YouTube URLã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡º
        """
        patterns = [
            r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)',
            r'youtube\.com\/watch\?.*v=([^&\n?#]+)'
        ]
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        return None

    def get_video_info(self, video_id: str) -> Dict[str, Any]:
        """
        YouTubeå‹•ç”»ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
        """
        if not self.youtube_client:
            raise Exception("YouTube APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        try:
            # å‹•ç”»æƒ…å ±
            video_response = self.youtube_client.videos().list(
                part='snippet,statistics,contentDetails', id=video_id
            ).execute()
            if not video_response.get('items'):
                raise Exception(f"å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_id}")
            video_data = video_response['items'][0]

            # ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±
            channel_id = video_data['snippet']['channelId']
            channel_response = self.youtube_client.channels().list(
                part='snippet,statistics', id=channel_id
            ).execute()
            channel_data = channel_response['items'][0] if channel_response.get('items') else {}

            # ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—
            comments = []
            try:
                comment_response = self.youtube_client.commentThreads().list(
                    part='snippet', videoId=video_id, maxResults=100, order='relevance'
                ).execute()
                for item in comment_response['items']:
                    comment = item['snippet']['topLevelComment']['snippet']
                    comments.append({
                        'author': comment['authorDisplayName'],
                        'text': comment['textDisplay'],
                        'like_count': comment['likeCount'],
                        'published_at': comment['publishedAt']
                    })
            except HttpError as e:
                logger.warning(f"ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e} (ã‚³ãƒ¡ãƒ³ãƒˆãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™)")

            return self._format_video_info(video_data, channel_data, comments)
        except Exception as e:
            logger.error(f"å‹•ç”»æƒ…å ±å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise

    def _format_video_info(self, video_data, channel_data, comments):
        snippet = video_data.get('snippet', {})
        stats = video_data.get('statistics', {})
        details = video_data.get('contentDetails', {})
        ch_snippet = channel_data.get('snippet', {})
        ch_stats = channel_data.get('statistics', {})

        return {
            'video_id': video_data.get('id'),
            'title': snippet.get('title'),
            'description': snippet.get('description'),
            'published_at': snippet.get('publishedAt'),
            'channel_id': snippet.get('channelId'),
            'channel_title': snippet.get('channelTitle'),
            'tags': snippet.get('tags', []),
            'view_count': int(stats.get('viewCount', 0)),
            'like_count': int(stats.get('likeCount', 0)),
            'comment_count': int(stats.get('commentCount', 0)),
            'duration_iso': details.get('duration', 'PT0S'),
            'duration_sec': self._convert_iso8601_duration(details.get('duration', 'PT0S')),
            'comments': comments,
            'channel_info': {
                'title': ch_snippet.get('title'),
                'subscriber_count': int(ch_stats.get('subscriberCount', 0)),
                'video_count': int(ch_stats.get('videoCount', 0)),
                'view_count': int(ch_stats.get('viewCount', 0)),
            }
        }

    def _convert_iso8601_duration(self, duration_str: str) -> int:
        """ISO 8601å½¢å¼ã®æ™‚é–“ã‚’ç§’ã«å¤‰æ›"""
        if not duration_str.startswith('PT'):
            return 0
        
        duration_str = duration_str[2:]
        total_seconds = 0
        
        time_matches = re.match(r'(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration_str)
        if time_matches:
            hours = int(time_matches.group(1) or 0)
            minutes = int(time_matches.group(2) or 0)
            seconds = int(time_matches.group(3) or 0)
            total_seconds = hours * 3600 + minutes * 60 + seconds
            
        return total_seconds

    def download_video(self, url: str, output_format: str = 'mp4') -> Dict[str, Any]:
        """
        yt-dlpã‚’ä½¿ç”¨ã—ã¦å‹•ç”»ã¨é–¢é€£æƒ…å ±ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        """
        video_id = self.extract_video_id(url)
        if not video_id:
            raise ValueError("ç„¡åŠ¹ãªYouTube URLã§ã™")

        output_path = os.path.join(self.temp_dir, f"{video_id}.{output_format}")
        
        ydl_opts = {
            'format': f'bestvideo[ext={output_format}]+bestaudio/best[ext={output_format}]/best',
            'outtmpl': os.path.join(self.temp_dir, f'{video_id}.%(ext)s'),
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': ['ja', 'en'],
            'subtitlesformat': 'vtt',
            'quiet': True,
            'no_warnings': True,
            'merge_output_format': output_format,
        }
        
        logger.info(f"å‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {url}")
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=True)
                
                # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç‰¹å®š
                actual_video_path = ydl.prepare_filename(info)
                subtitle_path = self._find_file_by_extension(video_id, '.vtt')

                logger.info(f"å‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {actual_video_path}")
                return {
                    'success': True,
                    'video_path': actual_video_path,
                    'subtitle_path': subtitle_path,
                    'duration': info.get('duration', 0),
                    'title': info.get('title', ''),
                }
        except Exception as e:
            logger.error(f"å‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}

    def _find_file_by_extension(self, video_id: str, extension: str) -> Optional[str]:
        """æŒ‡å®šã•ã‚ŒãŸæ‹¡å¼µå­ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ¢ã™"""
        for lang in ['ja', 'en']:
            expected_path = os.path.join(self.temp_dir, f"{video_id}.{lang}{extension}")
            if os.path.exists(expected_path):
                return expected_path
        # è¨€èªæŒ‡å®šãªã—ã®ãƒ‘ã‚¹ã‚‚ç¢ºèª
        expected_path = os.path.join(self.temp_dir, f"{video_id}{extension}")
        if os.path.exists(expected_path):
            return expected_path
        return None

    def parse_subtitle(self, subtitle_path: str) -> str:
        """
        å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«(VTT)ã‚’è§£æã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        """
        if not subtitle_path or not os.path.exists(subtitle_path):
            return ""
        try:
            with open(subtitle_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¡Œã¨ç©ºè¡Œã‚’é™¤å¤–
            text_lines = [line.strip() for line in lines if line.strip() and '-->' not in line and not line.strip().isdigit() and 'WEBVTT' not in line]
            
            # é‡è¤‡ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆè¡Œã‚’å‰Šé™¤
            unique_lines = []
            for line in text_lines:
                if not unique_lines or unique_lines[-1] != line:
                    unique_lines.append(line)

            return ' '.join(unique_lines)
        except Exception as e:
            logger.error(f"å­—å¹•è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return ""

    def analyze_video_comprehensive(self, url: str, download_video: bool = True) -> Dict[str, Any]:
        """
        å‹•ç”»ã®åŒ…æ‹¬çš„åˆ†æã‚’å®Ÿè¡Œã—ã€æŒ‡å®šã•ã‚ŒãŸå½¢å¼ã§çµæœã‚’è¿”ã™
        """
        start_time = datetime.now()
        logger.info(f"åŒ…æ‹¬çš„åˆ†æé–‹å§‹: {url}")
        
        video_id = self.extract_video_id(url)
        if not video_id:
            raise ValueError("ç„¡åŠ¹ãªYouTube URLã§ã™")

        # 1. å‹•ç”»æƒ…å ±å–å¾—
        video_info = self.get_video_info(video_id)
        
        # 2. å‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨å­—å¹•å–å¾—
        subtitle_text = ""
        technical_quality_score = 50.0 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        if download_video:
            download_result = self.download_video(url)
            if download_result.get('success'):
                subtitle_text = self.parse_subtitle(download_result.get('subtitle_path'))
                # ã“ã“ã§æŠ€è¡“å“è³ªã‚’è©•ä¾¡ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ å¯èƒ½ (ä»Šå›ã¯ãƒ€ãƒŸãƒ¼)
                technical_quality_score = 85.0 # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸæ™‚ã®ä»®ã‚¹ã‚³ã‚¢
            else:
                logger.warning("å‹•ç”»ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸãŸã‚ã€å­—å¹•ãªã—ã§åˆ†æã‚’ç¶šè¡Œã—ã¾ã™ã€‚")

        # 3. Geminiã«ã‚ˆã‚‹åŒ…æ‹¬çš„åˆ†æ
        gemini_full_analysis = self.gemini_analyzer.analyze_video_fully(
            transcript=subtitle_text,
            comments=video_info.get('comments', []),
            video_duration=video_info.get('duration_sec', 0)
        )
        if "error" in gemini_full_analysis:
            logger.error(f"Geminiåˆ†æã§ã‚¨ãƒ©ãƒ¼: {gemini_full_analysis['error']}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã§ã‚‚å‡¦ç†ã‚’ç¶šã‘ã‚‹ãŸã‚ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ§‹é€ ã‚’è¿”ã™
            raise Exception(f"Gemini analysis failed: {gemini_full_analysis['error']}")

        # 4. VVPã‚¹ã‚³ã‚¢è¨ˆç®—
        vvp_score_result = self.vvp_calculator.calculate_vvp_score(
            gemini_kpis=gemini_full_analysis.get('vvp_scores', {}),
            tech_quality_score=technical_quality_score
        )

        # 5. åˆ‡ã‚ŠæŠœãå€™è£œãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆ
        engagement_hotspots = self.vvp_calculator.extract_timestamps_from_comments(video_info.get('comments', []))
        gemini_hotspots = gemini_full_analysis.get('top_clips_semantic_analysis', [])
        clip_ranking = self.vvp_calculator.calculate_clip_scores(engagement_hotspots, gemini_hotspots)

        # 6. ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™ã¨æ„Ÿæƒ…åˆ†æ
        engagement_metrics = self.vvp_calculator.calculate_engagement_metrics(video_info.get('comments', []))
        
        # 7. æœ€çµ‚å‡ºåŠ›ã®æ•´å½¢
        final_report = {
            "vvp_score": vvp_score_result.get('total_vvp_score'),
            "vvp_score_details": vvp_score_result,
            "golden_clip_suggestion": gemini_full_analysis.get('golden_clip_suggestion'),
            "clip_candidates_ranking": clip_ranking[:10], # ä¸Šä½10ä»¶
            "sentiment_analysis": {
                "sentiment_distribution": engagement_metrics.get('sentiment_distribution'),
                "summary": f"ã‚³ãƒ¡ãƒ³ãƒˆç·æ•°{engagement_metrics.get('total_comments')}ä»¶ã«åŸºã¥ãæ„Ÿæƒ…åˆ†æçµæœã§ã™ã€‚"
            },
            "engagement_metrics": engagement_metrics,
            "technical_quality_assessment": {
                "score": technical_quality_score,
                "summary": "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ãæŠ€è¡“è©•ä¾¡ã§ã™ã€‚" + ("(ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æœªå®Ÿæ–½ã®ãŸã‚ãƒ€ãƒŸãƒ¼å€¤)" if not download_video else "")
            },
            "full_gemini_analysis": gemini_full_analysis, # è©³ç´°ãªGeminiåˆ†æçµæœã‚‚æ ¼ç´
            "source_video_info": video_info,
        }
        
        processing_time = (datetime.now() - start_time).total_seconds()
        logger.info(f"åŒ…æ‹¬çš„åˆ†æå®Œäº†ã€‚å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        
        return final_report

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç®¡ç†
_analyzer_instance = None

def get_analyzer_instance(youtube_api_key: str, gemini_api_key: str) -> "IntegratedYouTubeAnalyzer":
    """
    åˆ†æå™¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    """
    global _analyzer_instance
    if _analyzer_instance is None or _analyzer_instance.youtube_api_key != youtube_api_key:
        logger.info("æ–°ã—ã„çµ±åˆåˆ†æå™¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚")
        _analyzer_instance = IntegratedYouTubeAnalyzer(youtube_api_key, gemini_api_key)
    return _analyzer_instance

if __name__ == '__main__':
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨ã®ã‚³ãƒ¼ãƒ‰
    if len(sys.argv) < 4:
        print("ä½¿ç”¨æ–¹æ³•: python youtube_analyzer_integrated.py <YouTube_URL> <YouTube_API_Key> <Gemini_API_Key>")
        sys.exit(1)
    
    test_url = sys.argv[1]
    test_yt_key = sys.argv[2]
    test_gemini_key = sys.argv[3]
    
    print("çµ±åˆYouTubeå‹•ç”»åˆ†æã‚·ã‚¹ãƒ†ãƒ  - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("=" * 60)
    
    try:
        analyzer = get_analyzer_instance(test_yt_key, test_gemini_key)
        final_result = analyzer.analyze_video_comprehensive(test_url, download_video=True)
        
        # çµæœã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã§å‡ºåŠ›
        print("\n--- æœ€çµ‚åˆ†æãƒ¬ãƒãƒ¼ãƒˆ ---")
        print(f"ğŸ“ˆ ç·åˆVVPã‚¹ã‚³ã‚¢: {final_result['vvp_score']}/100")
        
        print("\nğŸ’ ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒªãƒƒãƒ—ææ¡ˆ:")
        golden_clip = final_result['golden_clip_suggestion']
        print(f"   - æ™‚é–“: {golden_clip.get('time_range', 'N/A')}")
        print(f"   - ç†ç”±: {golden_clip.get('reason', 'N/A')}")

        print("\nğŸ¬ åˆ‡ã‚ŠæŠœãå€™è£œãƒˆãƒƒãƒ—5:")
        for i, clip in enumerate(final_result['clip_candidates_ranking'][:5]):
            print(f"   {i+1}. [{clip.get('clip_score')}ç‚¹] {clip.get('formatted_time', 'N/A')} - {clip.get('reason', 'N/A')} ({clip.get('mention_count')}å›è¨€åŠ)")

        print("\nâ¤ï¸ æ„Ÿæƒ…åˆ†æ:")
        sentiment = final_result['sentiment_analysis']['sentiment_distribution']
        print(f"   - ãƒã‚¸ãƒ†ã‚£ãƒ–: {sentiment.get('positive', 0):.1%}")
        print(f"   - ãƒã‚¬ãƒ†ã‚£ãƒ–: {sentiment.get('negative', 0):.1%}")
        print(f"   - ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«: {sentiment.get('neutral', 0):.1%}")

        print("\nğŸ“Š ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™:")
        engagement = final_result['engagement_metrics']
        print(f"   - ç·ã‚³ãƒ¡ãƒ³ãƒˆæ•°: {engagement.get('total_comments')}")
        print(f"   - ç·ã„ã„ã­æ•°ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆï¼‰: {engagement.get('total_likes')}")
        print("-" * 25)

    except Exception as e:
        logger.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if _analyzer_instance and os.path.exists(_analyzer_instance.temp_dir):
            import shutil
            shutil.rmtree(_analyzer_instance.temp_dir)
            logger.info(f"ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ: {_analyzer_instance.temp_dir}") 